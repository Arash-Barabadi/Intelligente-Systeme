# Intelligente-Systeme

# Multisensorik

# Laser scanner
### Ein Laserscanner (oder  LIDAR) ist ein Sensor, der Entfernungen zu Objekten misst, indem er Lichtimpulse aussendet und die Reflexion (also das zurÃ¼ckkommende Licht) misst. 

## Entfernungsmessung mit Laserlicht
### Der Scanner sendet Laserstrahlen aus. Diesen treffen auf ein Objekt und werden zurÃ¼ckreflektiert. Aus der Zeit, die der Lichstrahl braucht, um hin und zurÃ¼ck zu kommen (Laufzeitmessung), wird die entfernung berechnet. 

## Entfernung = c x t / 2  
### c : Lichtgeschwindigkeit (~300.000 km/s) , t: gemessene Laufzeit. 


## Ã–ffnungswinkel vernachlÃ¤ssigbar
### Das bedeutet: Der Laserstrahl ist sehr schmal (nahezu punktfÃ¶rmig). Er hat also kaum einen Ã–ffnungswinkel wie z. B. Radarwellen â€” dadurch ist die RÃ¤umliche AuflÃ¶sung sehr hoch (prÃ¤zise Messung kleiner Details).

## Reflektor erkenung 
### Der Scanner kann Reflektoren (z. B. Spiegel, reflektierende Markierungen) leicht erkennen, weil sie besonders starkes reflektiertes Signal zurÃ¼cksenden. Das wird z. B. genutzt zur Positionserkennung oder Navigation in Robotern (sie erkennen ihre Umgebung Ã¼ber fest installierte Reflektoren).


## Wie funktioniert er allgemein
### Der Laser schickt mehrere Strahlen in verschiedene Richtungen (meist durch rotierende Spiegel oder Drehbewegung). So wird die gesamte Umgebung Zeile fÃ¼r Zeile abgetastet und eine 3D-Punktwolke erstellt, die die Umgebung beschreibt.

## Begrenzungen des Laserscanners
### 1-Leistung des Lasers (StÃ¤rke)
#### Wenn der Laser zu schwach ist, kommt zu wenig Licht zurÃ¼ck â†’ Entfernungsmessung wird ungenau.
#### Zu stark â†’ kann blenden oder Reflexionsfehler verursachen.
### 2- Glas oder transparente OberflÃ¤chen
#### Glas reflektiert und bricht Licht gleichzeitig â†’ der Laserstrahl kann â€verlorenâ€œ gehen oder doppelt reflektiert werden. Deshalb erkennt LIDAR GlasflÃ¤chen oft nicht oder falsch.
### 3- Cross Talk (SignalÃ¼berschneidung)
#### Wenn mehrere Laserscanner in der NÃ¤he arbeiten, kÃ¶nnen ihre Signale sich Ã¼berlagern. Dieses Problem ist geringer als bei Radar, weil Laser sehr gerichtete Strahlen haben.

### Wie kann man das Reflektionsproblem lÃ¶sen?
### Filterung und Signalverarbeitung: Software kann schwache oder doppelte Reflexionen erkennen und herausfiltern.
### Neigung des Sensors Ã¤ndern: Ein leicht schrÃ¤ger Winkel reduziert Reflexionen auf GlasoberflÃ¤chen.
### Kombination mit anderen Sensoren: LIDAR + Kamera oder Radar â†’ Sensorfusion hilft, Glas oder transparente Objekte besser zu erkennen.
### WellenlÃ¤nge anpassen: Bestimmte WellenlÃ¤ngen (z. B. im nahen Infrarotbereich) haben weniger Probleme mit Reflexionen.

# ğŸš— Fahrkamera (Vehicle Camera)
## Fahrkameras sind Kameras, die in Fahrzeugen (z. B. Autos, Roboter, autonome Fahrzeuge) eingebaut werden, um die Umgebung visuell zu erfassen. Sie sind ein zentrales Element fÃ¼r Umfelderkennung, Spurhaltung, Hinderniserkennung und vieles mehr.

## Fahrbilder, Pendelnâ€“Tiltenâ€“Zoomen: Fahrbilder â†’ Das sind die Bilder, die die Kamera wÃ¤hrend der Fahrt aufnimmt.
## Sie dienen zur Analyse der StraÃŸe, Objekte, Verkehrsschilder usw.
## Pendelâ€“Tiltenâ€“Zoomen (PTZ) â†’ Das beschreibt die Bewegungsarten einer beweglichen Kamera:
## Pendel (Pan): Drehung nach links und rechts
## Tilten (Tilt): Neigung nach oben und unten
## Zoomen: VerÃ¤nderung des Sichtfeldes (VergrÃ¶ÃŸern oder Verkleinern)
## â¡ï¸ Eine PTZ-Kamera kann also den Bereich dynamisch anpassen, den sie Ã¼berwachen mÃ¶chte â€” z. B. einem Objekt folgen oder ein Verkehrsschild nÃ¤her heranzoomen.
## Mehrkamerasysteme, Erkennungsfachbereiche und Kanten
### Mehrkamerasysteme: Moderne Fahrzeuge haben mehrere Kameras (z. B. vorne, hinten, seitlich, oben) : Dadurch entsteht ein rundum-360Â°-Blickfeld.
### Die Daten mehrerer Kameras werden kombiniert (â€Sensorfusionâ€œ), um ein vollstÃ¤ndiges Bild der Umgebung zu erhalten.

### Erkennungsfachbereiche: Jede Kamera deckt einen bestimmten Erkennungsbereich ab (z. B. Frontkamera fÃ¼r Spur und Verkehrsschilder, RÃ¼ckkamera fÃ¼r Einparken). Zusammen decken sie alle wichtigen Sichtfelder ab.
### Kanten: In der Bildverarbeitung sind â€Kantenâ€œ die ÃœbergÃ¤nge zwischen hell und dunkel, also Objektgrenzen. Kanten werden erkannt, um Formen, Fahrbahnmarkierungen oder Hindernisse zu identifizieren.

### Entefrnungskammera, Stereokammera

## Distanzkammera
### 3D- Absandsprofil
### Time-of-Flight messung mit laser. 
#### Alternativ dazu :
### Mustererkennung : spielconsolen, 

## Radar: 
### Entfernungsmessung mit Elektromagnetischen Wellen.
### Variation der Frequnezen, 
### nicthvernachlÃ¤ssigbar klein Relativgeschwindigkeit: ErkÃ¤ren Sie ....


## GNSS
### Sattelatennavigation, 
### Genauigkeit Ohne Referenzenstation 2m mit 2cm 
